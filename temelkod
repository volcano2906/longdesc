import streamlit as st
# -*- coding: utf-8 -*-
"""
Created on Tue Jul  4 00:21:16 2023

@author: volka
"""

from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager
from nltk.corpus import stopwords
from bs4 import BeautifulSoup
from google_play_scraper import app
import pandas as pd
from nltk import ngrams
import re


c = webdriver.ChromeOptions()
c.add_argument("start-maximized")
c.add_argument("--incognito")
c.add_argument("--headless") 


def kelimecevir(kelime):
    kelime = kelime.split()
    a = len(kelime)
    b = ""
    if a == 1:
        kelime = kelime[0]
        return str(kelime)
    elif a == 2:
        kelime.insert(1, "%20")
        kelime = "".join(kelime)
        return kelime
    elif a == 3:
        kelime.insert(1, "%20")
        kelime.insert(3, "%20")
        kelime = "".join(kelime)
        return kelime
    elif a == 4:
        kelime.insert(1, "%20")
        kelime.insert(3, "%20")
        kelime.insert(5, "%20")
        kelime = "".join(kelime)
        return kelime


d = input("write target keyword:")


url = "https://play.google.com/store/search?q=" + \
    kelimecevir(d)+"&c=apps&hl=en&gl=US"
    
url2="https://play.google.com/store/search?q="+d.replace(" ","%20")+"&c=apps&hl=en&gl=US"    



driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options=c)
driver.get(url)

links_games = []

elems = driver.find_elements_by_xpath("//a[@href]")
for elem in elems:
    if "details?id" in elem.get_attribute("href"):
        links_games.append((elem.get_attribute("href")))

links_games = list(dict.fromkeys(links_games))
driver.close()

stop_words = stopwords.words('english')
stop_words.extend(['we','you','com','$', 'from', 'subject', 're', 'edu', 'use', 'best', 'us', "puzzle", "mojo", "unfold", "mojito",
                  "you", "your", "a", "1", "2", "3", "4", "5", "6", "7", "8", "9", "0", "about", "above", "after", "again", "against"])

def sembolkaldƒ±r(k):
    symbols = "!‚Äì\"#$%&()*‚Äù+‚úì-./‚Äú:$;<=>üòä?@[\]^_üòâ`-{|¬∑}~\n,.‚Äò'ü•∞‚Äô‚û°Ô∏è&üèÜüíéüéâüì±üìùüé®üñºüè∑üìåüíØüì∑üåà‚≠ê‚òÜüëçüéä‚úÖüî•‚úîüì£‚òÖ‚Ä¢‚Äî‚óÜ¬Æ‚ù§‚óè"
    for i in symbols:
        k = k.replace(i, '').replace("  ", " ")
    return k

link_games_2 = [m.split("=")[1] for m in links_games]

list_all_elements = []
ba≈ülƒ±klar = []
kƒ±saba≈ülƒ±k = []
uzun_a√ßƒ±klama = []
links_games_1 = []
developer_mail = []
reviews_meta=[]
comments=[]

def metadadatav2():
    for i in link_games_2:
        result = app(
            i,
            lang='en',  # defaults to 'en'
            country='us'
        )  # defaults to 'us'
        title = (result["title"])
        score = (result["score"])
        ratings = (result["ratings"])
        reviews = (result["reviews"])
        short_desc = (result["summary"])
        install = (result["installs"])
        comment = (result["comments"])
        # description=(BeautifulSoup(result["description"], "lxml").text) #orjinal hali burada
        description = (
            " ".join((BeautifulSoup(result["description"], "lxml").text).split()))
        long_len = len(description.split())
        developer_mail.append(result["developerEmail"])
        t√ºmveri = [title, short_desc, description,
                   long_len, install, score, ratings, reviews]
        list_all_elements.append(t√ºmveri)
        ba≈ülƒ±klar.append(title)
        kƒ±saba≈ülƒ±k.append(short_desc)
        comments.append(comment)
        uzun_a√ßƒ±klama.append(description)


metadadatav2()


docs = []
docs = uzun_a√ßƒ±klama[0:10]
docs_k√º√ß√ºk=[]
docs_k√º√ß√ºk = [docs_k√º√ß√ºk.append(d.lower()) for d in docs]
doc_uzun_a√ßƒ±klamalar_t√ºm = " ".join(docs)
doc_uzun_a√ßƒ±klamalar_t√ºm_nonsembol = re.sub(r'\W+', ' ', doc_uzun_a√ßƒ±klamalar_t√ºm)
doc_uzun_a√ßƒ±klamalar_t√ºm_nonsembol_split = doc_uzun_a√ßƒ±klamalar_t√ºm_nonsembol.split()
doc_uzun_a√ßƒ±klamalar_t√ºm_nonsembol_non_stop = [word for word in doc_uzun_a√ßƒ±klamalar_t√ºm_nonsembol_split if word.lower() not in stop_words]
doc_uzun_a√ßƒ±klamalar_t√ºm_nonsembol_non_stop=" ".join(doc_uzun_a√ßƒ±klamalar_t√ºm_nonsembol_non_stop)


def ngram(text):
    ngram_tek=[]
    for i in range(1,4):
        if i == 1:    
            n_grams = ngrams((text).split(), i)
            for a in n_grams:
                ngram_tek.append((a))
        if i == 2:    
            n_grams = ngrams((text).split(), i)
            for a in n_grams:
                ngram_tek.append(" ".join((a)))
        if i == 3:    
            n_grams = ngrams((text).split(), i)
            for a in n_grams:
                ngram_tek.append(" ".join((a)))

    return ngram_tek
    
              
t√ºm_data = ngram(doc_uzun_a√ßƒ±klamalar_t√ºm_nonsembol_non_stop.lower())

# Remove symbols from tuples in the list
cleaned_t√ºm_data = []

for item in t√ºm_data:
    if (str(item).replace("(", "").replace(")", "").replace(",", "").replace("'", "")) not in stop_words:
        cleaned_t√ºm_data.append((str(item).replace("(", "").replace(")", "").replace(",", "").replace("'", "")))

df = pd.DataFrame({'Keyword': cleaned_t√ºm_data})
df = df.drop_duplicates(subset='Keyword')

ngram_tek_ka√ß=dict((x, cleaned_t√ºm_data.count(x)) for x in set(cleaned_t√ºm_data))
df_2 = pd.DataFrame(list(ngram_tek_ka√ß.items()),columns = ['Keyword','Count'])
df = pd.merge(df,df_2, on='Keyword')
df = df.sort_values('Count', ascending=False)
  


keywords_to_remove = ['https', 'privacy', 'www']

# Create new columns
df['one word'] = df['Keyword'].apply(lambda x: "One word" if len(x.split()) == 1 else '')
df['two word'] = df['Keyword'].apply(lambda x: "Two word" if len(x.split()) == 2 else '')
df['three word'] = df['Keyword'].apply(lambda x: "Three word" if len(x.split()) == 3 else '')


# Create a new column for count data
df['Exist in Long Description'] = 0

def kontrol():
    for index, row in df.iterrows():
        ac=0
        av=row["Keyword"]
        for ab in docs:
            if re.findall('\\b'+av+'\\b', ab.lower()):
                ac=ac+1
        df.at[index, 'Exist in Long Description'] = ac

kontrol()
df=df[df['Exist in Long Description'] > 2]
df=df[df['Count'] > 2]
df = df.sort_values(by='Keyword', key=lambda x: x.str.len(), ascending=False).reset_index(drop=True)



def kontrol_keyword_usage2(gelen_comp_dic,df):
    df = df.sort_values(by='Keyword', key=lambda x: x.str.len(), ascending=False).reset_index(drop=True)
    df['adjust count'] = 0
    for competitor, long_description in gelen_comp_dic.items():
        long_description_2=long_description
        long_description_nonsembol = re.sub(r'\W+', ' ', long_description_2)
        long_description_leng=len(long_description_nonsembol.split())
        longdescriptionLower=long_description.lower()
        for index, row in df.iterrows():
            sayƒ±=0
            av=row["Keyword"]
            if re.findall('\\b'+av+'\\b', longdescriptionLower):
                sayƒ± = len([*re.finditer('\\b'+av+'\\b', longdescriptionLower)])
                longdescriptionLower = re.sub('\\b'+av+'\\b', "", longdescriptionLower)
            df.at[index, 'adjust count'] = sayƒ±
            df.at[index, competitor ] = round((sayƒ±/long_description_leng)*100,1)
            if long_description_leng > 0:
                df.at[index, competitor] = round((sayƒ± / long_description_leng) * 100, 1)
            else:
                df.at[index, competitor] = 0

def kontrol_keyword_usage(gelen_comp_dic):
    for competitor, long_description in gelen_comp_dic.items():
        long_description_2=long_description
        long_description_nonsembol = re.sub(r'\W+', ' ', long_description_2)
        long_description_leng=len(long_description_nonsembol.split())
        longdescriptionLower=long_description.lower()
        df['adjust count'] = 0
        print(longdescriptionLower)
        for index, row in df.iterrows():
            sayƒ±=0
            av=row["Keyword"]
            if re.findall('\\b'+av+'\\b', longdescriptionLower):
                sayƒ± = len([*re.finditer('\\b'+av+'\\b', longdescriptionLower)])
                print(sayƒ±,av)
                longdescriptionLower = re.sub('\\b'+av+'\\b', "", longdescriptionLower)
            df.at[index, competitor ] = round((sayƒ±/long_description_leng)*100,1)


# Example usage
# kontrol_keyword_usage(gelen_comp_dic, df)


competitor_dic={"Competitor":docs[0],"Competitor-1":docs[1],"Competitor-2":docs[2],"Competitor-3":docs[3],"Competitor-4":docs[4],"Competitor-5":docs[5],"Competitor-6":docs[6],"Competitor-7":docs[7],"Competitor-8":docs[8],"Competitor-9":docs[9]}
kontrol_keyword_usage(competitor_dic)
df = df[~df['Keyword'].str.contains('|'.join(keywords_to_remove))]
df['Average Percentage'] = df[['Competitor', 'Competitor-1', 'Competitor-2','Competitor-3', 'Competitor-4', 'Competitor-5','Competitor-6', 'Competitor-7', 'Competitor-8', 'Competitor-9']].apply(
    lambda row: round((row[row != 0].mean()),1), axis=1)

you_long=input("please write your data: ")

competitor_dic["You"]=you_long
kontrol_keyword_usage(competitor_dic,df)




def kontrol_you_competitor(df,current_long):
    current_long_2 = re.sub(r'\W+', ' ', current_long)
    current_long_2_len=len(current_long_2.split())
    for index, row in df.iterrows():
        sayƒ±=0
        av=row["Keyword"]
        if re.findall('\\b'+av+'\\b', current_long.lower()):
            sayƒ± = len([*re.finditer('\\b'+av+'\\b', current_long.lower())])
        df.at[index, 'You']=round((sayƒ±/current_long_2_len)*100,1)
    filter_df=df[df['Exist in Long Description'] > 1]
    filter_df=filter_df[filter_df['Count'] > 1]    
    return filter_df
            
you_long=input("please write your data: ")
df3=kontrol_you_competitor(df,you_long)
df_kelime_listesi=df3["Keyword"].tolist()
for ac in df_kelime_listesi:
    print(ac)
